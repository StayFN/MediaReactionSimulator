{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Downloading with yt-dlp\n",
    "\n",
    "### Overview\n",
    "`yt-dlp` is a command-line program to download videos and audio from YouTube and other video hosting websites. It's a fork of `youtube-dlc` which in turn is a fork of `youtube-dl`. \n",
    "\n",
    "### Installation\n",
    "You can install `yt-dlp` using pip. It's a straightforward process:\n",
    "\n",
    "```bash\n",
    "pip install yt-dlp\n",
    "```\n",
    "\n",
    "**Note for Windows Users:** After installing, make sure to add the `Scripts` folder of pip to your system's PATH. This allows you to run `yt-dlp` from any directory in the command prompt.\n",
    "\n",
    "### Downloading Audio from YouTube Shorts\n",
    "To download just the audio from a YouTube Short, use the following command:\n",
    "\n",
    "```bash\n",
    "yt-dlp -x --audio-format wav [URL]\n",
    "```\n",
    "\n",
    "Replace `[URL]` with the actual URL of the YouTube Short. This command extracts the audio in `.wav` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Gregors File and extract the IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l9_8_pDTmis', 'QYEfTly0pTE', 'jYJTPqU66IY', 'dBsomKKHhtk', 'dTLYweJ08Tg', 'k9v_bsZUQRg', 'Js6ZUBSW6s0', '1AY9Sqt7yCg', 'f8a2tiHatCc', 'bnem7I5UkaA', 'aFJ1ThX8XHU', 'n7x4Jj9pdH8', 'LdoJnz_ZQyU', 'm5uJjHV_eVs', 'xN5OsH0UCmo', 'KiEErvcX_qo', 'NLvfrxL3YGA', 'nK-Hy0TxIik', 'yWJVX9MKrUM', 'd2EPEgWPn8Y']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('youtube_shorts_description.csv') \n",
    "\n",
    "# Extract the video IDs\n",
    "video_ids = df['Video ID'].tolist()\n",
    "\n",
    "# Print the video IDs (optional, for verification)\n",
    "print(video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download them using yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Create the \"audio\" directory if it doesn't exist\n",
    "audio_dir = './audio'\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "# Base URL for YouTube shorts\n",
    "base_url = 'https://www.youtube.com/shorts/'\n",
    "\n",
    "# Loop through each video ID\n",
    "for video_id in video_ids:\n",
    "    # Construct the full URL\n",
    "    video_url = base_url + video_id\n",
    "\n",
    "    # Construct the yt-dlp command with output template\n",
    "    command = (\n",
    "        f'yt-dlp -x --audio-format wav --no-check-certificate '\n",
    "        f'-o \"{audio_dir}/%(title)s.%(ext)s\" {video_url}'\n",
    "    )\n",
    "\n",
    "    # Execute the command\n",
    "    subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Pretrained Model\n",
    "\n",
    "(Download the model from https://huggingface.co/ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition/resolve/main/pytorch_model.bin?download=true )\n",
    "To be able to manually set the weights and biases (seems like it isn't initialized correctly when just loading it from pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'classifier.output.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition and are newly initialized: ['classifier.bias', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# https://github.com/ehcalabres/EMOVoice\n",
    "# the preprocessor was derived from https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english\n",
    "# processor1 = AutoProcessor.from_pretrained(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\")\n",
    "# ^^^ no preload model available for this model (above), but the `feature_extractor` works in place\n",
    "model1 = AutoModelForAudioClassification.from_pretrained(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\")\n",
    "\n",
    "\n",
    "model1.projector = nn.Linear(1024, 1024, bias=True)\n",
    "model1.classifier = nn.Linear(1024, 8, bias=True)\n",
    "#\n",
    "##https://huggingface.co/ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition/resolve/main/pytorch_model.bin?download=true\n",
    "torch_state_dict = torch.load('pytorch_model.bin', map_location=torch.device('cpu'))\n",
    "#\n",
    "model1.projector.weight.data = torch_state_dict['classifier.dense.weight']\n",
    "model1.projector.bias.data = torch_state_dict['classifier.dense.bias']\n",
    "#\n",
    "model1.classifier.weight.data = torch_state_dict['classifier.output.weight']\n",
    "model1.classifier.bias.data = torch_state_dict['classifier.output.bias']\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
    "\n",
    "def predict_emotion(audio_file):\n",
    "    if not audio_file:\n",
    "        # I fetched some samples with known emotions from here: https://www.fesliyanstudios.com/royalty-free-sound-effects-download/poeple-crying-252\n",
    "        audio_file = 'MrBeast.wav'\n",
    "    sound = AudioSegment.from_file(audio_file)\n",
    "    sound = sound.set_frame_rate(16000)\n",
    "    sound_array = np.array(sound.get_array_of_samples())\n",
    "    # this model is VERY SLOW, so best to pass in small sections that contain \n",
    "    # emotional words from the transcript. like 10s or less.\n",
    "    # how to make sub-chunk  -- this was necessary even with very short audio files \n",
    "    # test = torch.tensor(input.input_values.float()[:, :100000])\n",
    "\n",
    "    input = feature_extractor(\n",
    "        raw_speech=sound_array,\n",
    "        sampling_rate=16000,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "    result = model1.forward(input.input_values.float())\n",
    "    # making sense of the result \n",
    "    id2label = {\n",
    "        \"0\": \"angry\",\n",
    "        \"1\": \"calm\",\n",
    "        \"2\": \"disgust\",\n",
    "        \"3\": \"fearful\",\n",
    "        \"4\": \"happy\",\n",
    "        \"5\": \"neutral\",\n",
    "        \"6\": \"sad\",\n",
    "        \"7\": \"surprised\"\n",
    "    }\n",
    "    interp = dict(zip(id2label.values(), list(round(float(i),4) for i in result[0][0])))\n",
    "    return interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': -2.4137,\n",
       " 'calm': 4.3917,\n",
       " 'disgust': 1.8303,\n",
       " 'fearful': -1.7471,\n",
       " 'happy': -1.725,\n",
       " 'neutral': 0.0457,\n",
       " 'sad': 4.0059,\n",
       " 'surprised': -3.7045}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(\"cry.wav\") # Audio of crying man"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [39:45<00:00, 119.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             filename  \\\n",
      "0                        A Real Authentic Italian.wav   \n",
      "1   Chinese Spacecraft Rolls Out Of Control During...   \n",
      "2   Corrupt Cops Caught & OWNED! Dirty Tyrant Stat...   \n",
      "3   Courtside Kicks CASHES OUT on WHOLE TABLE of D...   \n",
      "4                                 enjoy the light.wav   \n",
      "5   FINDING TOM HOLLAND ðŸ˜‚ðŸ˜‚ #marvel #mcu #spiderman...   \n",
      "6              Furthest Away From Me Wins $10,000.wav   \n",
      "7    Hockey Cameramen are Insane (@lsantanaphoto).wav   \n",
      "8   How much do #Teachers makeï¼Ÿ #salarycompilation...   \n",
      "9                How to renovate your private jet.wav   \n",
      "10                how to set the perfect password.wav   \n",
      "11                                 Kid Fried Rice.wav   \n",
      "12               Spending $100 in North Macedonia.wav   \n",
      "13  Typing SO FAST that monkeytype would INVALIDAT...   \n",
      "14                       Ultra Efficient Pit Stop.wav   \n",
      "15                      WAKE UPï¼š College Is A Lie.wav   \n",
      "16  We lost contact with ATC over the ocean! #avia...   \n",
      "17          When you finally meet the ï¼‚work wifeï¼‚.wav   \n",
      "18  Why Does This GENIUS Business Idea Not Existï¼Ÿ!...   \n",
      "19                     Worldâ€™s Most Expensive Bed.wav   \n",
      "\n",
      "                                           prediction  \n",
      "0   {'angry': -2.078, 'calm': 2.7263, 'disgust': 2...  \n",
      "1   {'angry': -1.7527, 'calm': 2.133, 'disgust': 2...  \n",
      "2   {'angry': -2.2896, 'calm': 2.9672, 'disgust': ...  \n",
      "3   {'angry': -2.0477, 'calm': 2.9957, 'disgust': ...  \n",
      "4   {'angry': -2.114, 'calm': 2.7554, 'disgust': 2...  \n",
      "5   {'angry': -2.1089, 'calm': 2.8699, 'disgust': ...  \n",
      "6   {'angry': -2.2997, 'calm': 3.157, 'disgust': 1...  \n",
      "7   {'angry': -2.1661, 'calm': 3.078, 'disgust': 2...  \n",
      "8   {'angry': -1.9655, 'calm': 2.2441, 'disgust': ...  \n",
      "9   {'angry': -2.373, 'calm': 3.3454, 'disgust': 1...  \n",
      "10  {'angry': -2.0213, 'calm': 2.8222, 'disgust': ...  \n",
      "11  {'angry': -1.6296, 'calm': 1.8849, 'disgust': ...  \n",
      "12  {'angry': -2.12, 'calm': 2.6141, 'disgust': 2....  \n",
      "13  {'angry': -1.8579, 'calm': 2.2404, 'disgust': ...  \n",
      "14  {'angry': -2.4172, 'calm': 2.8881, 'disgust': ...  \n",
      "15  {'angry': -1.8777, 'calm': 2.4575, 'disgust': ...  \n",
      "16  {'angry': -2.3371, 'calm': 3.3723, 'disgust': ...  \n",
      "17  {'angry': -2.2784, 'calm': 3.0083, 'disgust': ...  \n",
      "18  {'angry': -2.0843, 'calm': 2.2663, 'disgust': ...  \n",
      "19  {'angry': -2.0999, 'calm': 3.0483, 'disgust': ...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming the 'predict_emotion' function is already defined\n",
    "\n",
    "# Path to the 'audio' directory\n",
    "audio_dir = './audio'\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over each file in the 'audio' folder with a progress bar\n",
    "for filename in tqdm(os.listdir(audio_dir), desc=\"Processing audio files\"):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Full path of the audio file\n",
    "        file_path = os.path.join(audio_dir, filename)\n",
    "\n",
    "        # Call the predict_emotion function\n",
    "        emotion_prediction = predict_emotion(file_path)\n",
    "\n",
    "        # Append the results along with the filename\n",
    "        results.append({'filename': filename, 'prediction': emotion_prediction})\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Real Authentic Italian.wav</td>\n",
       "      <td>{'angry': -2.078, 'calm': 2.7263, 'disgust': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chinese Spacecraft Rolls Out Of Control During...</td>\n",
       "      <td>{'angry': -1.7527, 'calm': 2.133, 'disgust': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corrupt Cops Caught &amp; OWNED! Dirty Tyrant Stat...</td>\n",
       "      <td>{'angry': -2.2896, 'calm': 2.9672, 'disgust': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Courtside Kicks CASHES OUT on WHOLE TABLE of D...</td>\n",
       "      <td>{'angry': -2.0477, 'calm': 2.9957, 'disgust': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enjoy the light.wav</td>\n",
       "      <td>{'angry': -2.114, 'calm': 2.7554, 'disgust': 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0                       A Real Authentic Italian.wav   \n",
       "1  Chinese Spacecraft Rolls Out Of Control During...   \n",
       "2  Corrupt Cops Caught & OWNED! Dirty Tyrant Stat...   \n",
       "3  Courtside Kicks CASHES OUT on WHOLE TABLE of D...   \n",
       "4                                enjoy the light.wav   \n",
       "\n",
       "                                          prediction  \n",
       "0  {'angry': -2.078, 'calm': 2.7263, 'disgust': 2...  \n",
       "1  {'angry': -1.7527, 'calm': 2.133, 'disgust': 2...  \n",
       "2  {'angry': -2.2896, 'calm': 2.9672, 'disgust': ...  \n",
       "3  {'angry': -2.0477, 'calm': 2.9957, 'disgust': ...  \n",
       "4  {'angry': -2.114, 'calm': 2.7554, 'disgust': 2...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    angry    calm  disgust  fearful   happy  neutral     sad  surprised\n",
      "0 -2.0780  2.7263   2.2574  -1.1500 -1.5450  -0.3969  4.6464    -3.8677\n",
      "1 -1.7527  2.1330   2.9519  -1.2306 -1.5955  -0.8280  4.6259    -3.6894\n",
      "2 -2.2896  2.9672   1.9130  -1.0142 -1.5379  -0.3028  4.8103    -3.9737\n",
      "3 -2.0477  2.9957   2.0203  -1.2569 -1.4550  -0.1416  4.4973    -4.0577\n",
      "4 -2.1140  2.7554   2.4861  -1.1827 -1.7141  -0.5673  4.7852    -3.7833\n",
      "      angry      calm   disgust   fearful     happy   neutral       sad  \\\n",
      "0  0.430675  0.565685  0.387902  0.373323  0.652644  0.704034  0.318658   \n",
      "1  0.843702  0.166801  0.834813  0.266242  0.457738  0.204266  0.274845   \n",
      "2  0.162011  0.727646  0.166281  0.553740  0.680046  0.813123  0.668946   \n",
      "3  0.469147  0.746807  0.235328  0.231301  1.000000  1.000000  0.000000   \n",
      "4  0.384967  0.585249  0.535071  0.329879  0.000000  0.506492  0.615302   \n",
      "\n",
      "   surprised  \n",
      "0   0.392238  \n",
      "1   0.760322  \n",
      "2   0.173410  \n",
      "3   0.000000  \n",
      "4   0.566474  \n"
     ]
    }
   ],
   "source": [
    "#Scale the results, since it seems like they are all in a similar range of values\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample DataFrame\n",
    "\n",
    "# Convert the dictionary column into a DataFrame of its own\n",
    "emotion_df = df_results['prediction'].apply(pd.Series)\n",
    "\n",
    "# Display the new DataFrame structure\n",
    "print(emotion_df.head())\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize each column\n",
    "for column in emotion_df.columns:\n",
    "    emotion_df[column] = scaler.fit_transform(emotion_df[[column]])\n",
    "\n",
    "# Now emotion_df has normalized values for each emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>calm</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fearful</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430675</td>\n",
       "      <td>0.565685</td>\n",
       "      <td>0.387902</td>\n",
       "      <td>0.373323</td>\n",
       "      <td>0.652644</td>\n",
       "      <td>0.704034</td>\n",
       "      <td>0.318658</td>\n",
       "      <td>0.392238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843702</td>\n",
       "      <td>0.166801</td>\n",
       "      <td>0.834813</td>\n",
       "      <td>0.266242</td>\n",
       "      <td>0.457738</td>\n",
       "      <td>0.204266</td>\n",
       "      <td>0.274845</td>\n",
       "      <td>0.760322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.162011</td>\n",
       "      <td>0.727646</td>\n",
       "      <td>0.166281</td>\n",
       "      <td>0.553740</td>\n",
       "      <td>0.680046</td>\n",
       "      <td>0.813123</td>\n",
       "      <td>0.668946</td>\n",
       "      <td>0.173410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.469147</td>\n",
       "      <td>0.746807</td>\n",
       "      <td>0.235328</td>\n",
       "      <td>0.231301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384967</td>\n",
       "      <td>0.585249</td>\n",
       "      <td>0.535071</td>\n",
       "      <td>0.329879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506492</td>\n",
       "      <td>0.615302</td>\n",
       "      <td>0.566474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      angry      calm   disgust   fearful     happy   neutral       sad  \\\n",
       "0  0.430675  0.565685  0.387902  0.373323  0.652644  0.704034  0.318658   \n",
       "1  0.843702  0.166801  0.834813  0.266242  0.457738  0.204266  0.274845   \n",
       "2  0.162011  0.727646  0.166281  0.553740  0.680046  0.813123  0.668946   \n",
       "3  0.469147  0.746807  0.235328  0.231301  1.000000  1.000000  0.000000   \n",
       "4  0.384967  0.585249  0.535071  0.329879  0.000000  0.506492  0.615302   \n",
       "\n",
       "   surprised  \n",
       "0   0.392238  \n",
       "1   0.760322  \n",
       "2   0.173410  \n",
       "3   0.000000  \n",
       "4   0.566474  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Video Title</th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Words per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>d2EPEgWPn8Y</td>\n",
       "      <td>A Real Authentic Italian</td>\n",
       "      <td>Adriano Valentini</td>\n",
       "      <td>how am I the only one who's offended I'm offen...</td>\n",
       "      <td>121.360</td>\n",
       "      <td>1.821028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NLvfrxL3YGA</td>\n",
       "      <td>Chinese Spacecraft Rolls Out Of Control During...</td>\n",
       "      <td>Scott Manley</td>\n",
       "      <td>yesterday the three astronauts from China's sh...</td>\n",
       "      <td>121.760</td>\n",
       "      <td>1.544021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f8a2tiHatCc</td>\n",
       "      <td>Corrupt Cops Caught &amp; OWNED! Dirty Tyrant Stat...</td>\n",
       "      <td>People's Court Audit</td>\n",
       "      <td>y'all decked out in police gear for this yes s...</td>\n",
       "      <td>119.858</td>\n",
       "      <td>1.777103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dTLYweJ08Tg</td>\n",
       "      <td>Courtside Kicks CASHES OUT on WHOLE TABLE of D...</td>\n",
       "      <td>Courtside Kicks</td>\n",
       "      <td>yo what's good bro so you have a ton of dunks ...</td>\n",
       "      <td>59.679</td>\n",
       "      <td>1.524824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nK-Hy0TxIik</td>\n",
       "      <td>FINDING TOM HOLLAND ðŸ˜‚ðŸ˜‚ #marvel #mcu #spiderman...</td>\n",
       "      <td>SYNCSHOW</td>\n",
       "      <td>so I know one of you is Tom Holland are you To...</td>\n",
       "      <td>65.320</td>\n",
       "      <td>1.500306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Video ID                                        Video Title  \\\n",
       "19  d2EPEgWPn8Y                           A Real Authentic Italian   \n",
       "16  NLvfrxL3YGA  Chinese Spacecraft Rolls Out Of Control During...   \n",
       "8   f8a2tiHatCc  Corrupt Cops Caught & OWNED! Dirty Tyrant Stat...   \n",
       "4   dTLYweJ08Tg  Courtside Kicks CASHES OUT on WHOLE TABLE of D...   \n",
       "17  nK-Hy0TxIik  FINDING TOM HOLLAND ðŸ˜‚ðŸ˜‚ #marvel #mcu #spiderman...   \n",
       "\n",
       "           Channel Title                                         Transcript  \\\n",
       "19     Adriano Valentini  how am I the only one who's offended I'm offen...   \n",
       "16          Scott Manley  yesterday the three astronauts from China's sh...   \n",
       "8   People's Court Audit  y'all decked out in police gear for this yes s...   \n",
       "4        Courtside Kicks  yo what's good bro so you have a ton of dunks ...   \n",
       "17              SYNCSHOW  so I know one of you is Tom Holland are you To...   \n",
       "\n",
       "    Duration  Words per Second  \n",
       "19   121.360          1.821028  \n",
       "16   121.760          1.544021  \n",
       "8    119.858          1.777103  \n",
       "4     59.679          1.524824  \n",
       "17    65.320          1.500306  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sort the DataFrame by the 'title' column in ascending order (alphabetically)\n",
    "sorted_df = df.sort_values(by='Video Title', ascending=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Video Title</th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Words per Second</th>\n",
       "      <th>angry</th>\n",
       "      <th>calm</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fearful</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>d2EPEgWPn8Y</td>\n",
       "      <td>A Real Authentic Italian</td>\n",
       "      <td>Adriano Valentini</td>\n",
       "      <td>how am I the only one who's offended I'm offen...</td>\n",
       "      <td>121.360</td>\n",
       "      <td>1.821028</td>\n",
       "      <td>0.402869</td>\n",
       "      <td>0.782170</td>\n",
       "      <td>0.562741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.622305</td>\n",
       "      <td>0.123531</td>\n",
       "      <td>0.602395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NLvfrxL3YGA</td>\n",
       "      <td>Chinese Spacecraft Rolls Out Of Control During...</td>\n",
       "      <td>Scott Manley</td>\n",
       "      <td>yesterday the three astronauts from China's sh...</td>\n",
       "      <td>121.760</td>\n",
       "      <td>1.544021</td>\n",
       "      <td>0.101701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173616</td>\n",
       "      <td>0.241265</td>\n",
       "      <td>0.469317</td>\n",
       "      <td>0.965221</td>\n",
       "      <td>0.313529</td>\n",
       "      <td>0.193642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f8a2tiHatCc</td>\n",
       "      <td>Corrupt Cops Caught &amp; OWNED! Dirty Tyrant Stat...</td>\n",
       "      <td>People's Court Audit</td>\n",
       "      <td>y'all decked out in police gear for this yes s...</td>\n",
       "      <td>119.858</td>\n",
       "      <td>1.777103</td>\n",
       "      <td>0.573514</td>\n",
       "      <td>0.241495</td>\n",
       "      <td>0.455598</td>\n",
       "      <td>0.715292</td>\n",
       "      <td>0.669626</td>\n",
       "      <td>0.421748</td>\n",
       "      <td>0.670870</td>\n",
       "      <td>0.443435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dTLYweJ08Tg</td>\n",
       "      <td>Courtside Kicks CASHES OUT on WHOLE TABLE of D...</td>\n",
       "      <td>Courtside Kicks</td>\n",
       "      <td>yo what's good bro so you have a ton of dunks ...</td>\n",
       "      <td>59.679</td>\n",
       "      <td>1.524824</td>\n",
       "      <td>0.384967</td>\n",
       "      <td>0.585249</td>\n",
       "      <td>0.535071</td>\n",
       "      <td>0.329879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506492</td>\n",
       "      <td>0.615302</td>\n",
       "      <td>0.566474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nK-Hy0TxIik</td>\n",
       "      <td>FINDING TOM HOLLAND ðŸ˜‚ðŸ˜‚ #marvel #mcu #spiderman...</td>\n",
       "      <td>SYNCSHOW</td>\n",
       "      <td>so I know one of you is Tom Holland are you To...</td>\n",
       "      <td>65.320</td>\n",
       "      <td>1.500306</td>\n",
       "      <td>0.176232</td>\n",
       "      <td>0.755278</td>\n",
       "      <td>0.237001</td>\n",
       "      <td>0.453301</td>\n",
       "      <td>0.424161</td>\n",
       "      <td>0.800023</td>\n",
       "      <td>0.522334</td>\n",
       "      <td>0.365400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Video ID                                        Video Title  \\\n",
       "19  d2EPEgWPn8Y                           A Real Authentic Italian   \n",
       "16  NLvfrxL3YGA  Chinese Spacecraft Rolls Out Of Control During...   \n",
       "8   f8a2tiHatCc  Corrupt Cops Caught & OWNED! Dirty Tyrant Stat...   \n",
       "4   dTLYweJ08Tg  Courtside Kicks CASHES OUT on WHOLE TABLE of D...   \n",
       "17  nK-Hy0TxIik  FINDING TOM HOLLAND ðŸ˜‚ðŸ˜‚ #marvel #mcu #spiderman...   \n",
       "\n",
       "           Channel Title                                         Transcript  \\\n",
       "19     Adriano Valentini  how am I the only one who's offended I'm offen...   \n",
       "16          Scott Manley  yesterday the three astronauts from China's sh...   \n",
       "8   People's Court Audit  y'all decked out in police gear for this yes s...   \n",
       "4        Courtside Kicks  yo what's good bro so you have a ton of dunks ...   \n",
       "17              SYNCSHOW  so I know one of you is Tom Holland are you To...   \n",
       "\n",
       "    Duration  Words per Second     angry      calm   disgust   fearful  \\\n",
       "19   121.360          1.821028  0.402869  0.782170  0.562741  0.000000   \n",
       "16   121.760          1.544021  0.101701  1.000000  0.173616  0.241265   \n",
       "8    119.858          1.777103  0.573514  0.241495  0.455598  0.715292   \n",
       "4     59.679          1.524824  0.384967  0.585249  0.535071  0.329879   \n",
       "17    65.320          1.500306  0.176232  0.755278  0.237001  0.453301   \n",
       "\n",
       "       happy   neutral       sad  surprised  \n",
       "19  0.009649  0.622305  0.123531   0.602395  \n",
       "16  0.469317  0.965221  0.313529   0.193642  \n",
       "8   0.669626  0.421748  0.670870   0.443435  \n",
       "4   0.000000  0.506492  0.615302   0.566474  \n",
       "17  0.424161  0.800023  0.522334   0.365400  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the dataframes using their indices\n",
    "merged_df = pd.concat([sorted_df, emotion_df], axis=1)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('youtube_shorts_description_emotion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
